<<<<<<< HEAD
# Loan Prediction Pipeline

A comprehensive machine learning system for loan approval prediction using MySQL, MongoDB, FastAPI, and scikit-learn.

## ðŸŽ¯ Project Overview

This project implements a complete loan prediction pipeline that includes:
- **Database Design**: MySQL (relational) and MongoDB (NoSQL) hybrid approach inform of collections.
- **API Development**: FastAPI with full CRUD operations
- **Machine Learning**: Random Forest classifier for loan approval prediction
- **Data Pipeline**: End-to-end data processing and prediction workflow

## ðŸ“Š Dataset

The system uses a loan prediction dataset with:
- **614 loan applications** with 13 features
- **Target variable**: Loan_Status (Y/N for approved/rejected)
- **Features**: Gender, Married, Dependents, Education, Self_Employed, ApplicantIncome, CoapplicantIncome, LoanAmount, Loan_Amount_Term, Credit_History, Property_Area

## ðŸ—ï¸ Project Structure

```
Loan-Prediction-Pipeline/
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ mysql/
â”‚   â”‚   â”œâ”€â”€ schema.sql              # MySQL database schema
â”‚   â”‚   â”œâ”€â”€ stored_procedures.sql   # Stored procedures
â”‚   â”‚   â””â”€â”€ triggers.sql            # Database triggers
â”‚   â””â”€â”€ mongodb/
â”‚       â”œâ”€â”€ collections.js          # MongoDB collections
â”‚       â””â”€â”€ sample_data.js          # Sample data
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py                     # FastAPI application
â”‚   â”œâ”€â”€ models.py                   # Pydantic models
â”‚   â”œâ”€â”€ database.py                 # Database connections
â”‚   â””â”€â”€ requirements.txt            # API dependencies
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ model_training.py           # ML model training
â”‚   â”œâ”€â”€ prediction_script.py        # Prediction pipeline
â”‚   â””â”€â”€ loan_model.pkl              # Trained model (generated)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ ERD_diagram.md              # Entity Relationship Diagram
â”œâ”€â”€ data/
â”‚   â””â”€â”€ loan_prediction.csv         # Dataset
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ setup.py                    # Project setup script
â””â”€â”€ README.md                       # This file
```

## ðŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone the repository
git clone <repository-url>
cd Loan-Prediction-Pipeline

# Run setup script
python scripts/setup.py

# Install dependencies
pip install -r api/requirements.txt
```

### 2. Configure Databases

Edit the `.env` file with your database credentials:

```env
# MySQL Configuration
MYSQL_HOST=localhost
MYSQL_PORT=3306
MYSQL_USER=root
MYSQL_PASSWORD=your_password
MYSQL_DATABASE=loan_prediction_db

# MongoDB Configuration
MONGO_URI=mongodb://localhost:27017/
MONGO_DATABASE=loan_prediction_db
```

### 3. Initialize Databases

```bash
# MySQL (using MySQL client)
mysql -u root -p < database/mysql/schema.sql
mysql -u root -p < database/mysql/stored_procedures.sql
mysql -u root -p < database/mysql/triggers.sql

# MongoDB
mongo < database/mongodb/collections.js
mongo < database/mongodb/sample_data.js
```

### 4. Train the Model

```bash
cd ml
python model_training.py
```

### 5. Start the API

```bash
cd api
python main.py
```

The API will be available at `http://localhost:8000`

### 6. Run Predictions

```bash
cd ml
python prediction_script.py
```

## ðŸ“‹ Assignment Requirements Fulfilled

### âœ… Task 1: Database Design

#### MySQL Schema
- **4 Tables**: `loan_applications`, `loan_features`, `loan_predictions`, `loan_analytics`
- **Primary & Foreign Keys**: Properly defined with constraints
- **Stored Procedures**: 5 procedures for data validation and automation
- **Triggers**: 6 triggers for data validation and logging

#### MongoDB Collections
- **3 Collections**: `loan_applications`, `loan_predictions`, `loan_analytics`
- **JSON Schema Validation**: Comprehensive validation rules
- **Indexes**: Performance optimization indexes

#### ERD Diagram
- Complete Entity Relationship Diagram in `docs/ERD_diagram.md`
- Shows relationships between all tables and collections
- Includes constraints, indexes, and data flow

### âœ… Task 2: FastAPI CRUD Operations

#### Endpoints Implemented
- **POST** `/applications` - Create loan application
- **GET** `/applications` - Read applications with filtering
- **GET** `/applications/{loan_id}` - Read specific application
- **PUT** `/applications/{loan_id}` - Update application
- **DELETE** `/applications/{loan_id}` - Delete application
- **POST** `/predict` - ML prediction endpoint
- **GET** `/statistics` - Analytics and statistics
- **GET** `/mongo/*` - MongoDB data access

### âœ… Task 3: Prediction Script

#### Features Implemented
- **Data Fetching**: Fetches latest entry from API
- **Data Preparation**: Prepares data for ML model
- **Model Loading**: Loads trained model
- **Prediction**: Makes predictions using the model
- **Result Storage**: Saves prediction results

## ðŸ”§ API Endpoints

### Loan Applications
```bash
# Create application
POST /applications
{
  "loan_id": "LP001999",
  "gender": "Male",
  "married": "Yes",
  "dependents": "2",
  "education": "Graduate",
  "self_employed": "No",
  "applicant_income": 5000.0,
  "coapplicant_income": 2000.0,
  "loan_amount": 150.0,
  "loan_amount_term": 360,
  "credit_history": 1,
  "property_area": "Urban"
}

# Get applications with filtering
GET /applications?gender=Male&education=Graduate&limit=10

# Update application
PUT /applications/LP001999
{
  "applicant_income": 6000.0,
  "loan_status": "Y"
}

# Delete application
DELETE /applications/LP001999
```

### ML Predictions
```bash
# Make prediction
POST /predict
{
  "gender": "Male",
  "married": "Yes",
  "dependents": "2",
  "education": "Graduate",
  "self_employed": "No",
  "applicant_income": 5000.0,
  "coapplicant_income": 2000.0,
  "loan_amount": 150.0,
  "loan_amount_term": 360,
  "credit_history": 1,
  "property_area": "Urban"
}
```

### Analytics
```bash
# Get statistics
GET /statistics

# Get MongoDB data
GET /mongo/applications
GET /mongo/predictions
GET /mongo/analytics
```

## ðŸ§  Machine Learning

### Model Details
- **Algorithm**: Random Forest Classifier
- **Features**: 11 engineered features
- **Performance**: ~79% accuracy
- **Preprocessing**: Label encoding + Standard scaling

### Feature Engineering
- Total income calculation
- Income ratios
- Loan-to-income ratios
- Boolean flags for categorical variables

## ðŸ“Š Database Features

### MySQL Features
- **Stored Procedures**: Data validation, statistics, analytics
- **Triggers**: Automatic feature calculation, audit logging
- **Views**: Aggregated statistics and summaries
- **Constraints**: Data integrity and validation

### MongoDB Features
- **Schema Validation**: JSON schema for data integrity
- **Indexes**: Performance optimization
- **Flexible Schema**: Document-based storage
- **Aggregation**: Complex analytics queries

## ðŸ› ï¸ Development

### Prerequisites
- Python 3.8+
- MySQL 8.0+
- MongoDB 4.4+
- pip

### Installation
```bash
# Install dependencies
pip install -r api/requirements.txt

# Setup databases
python scripts/setup.py
```

### Testing
```bash
# Test API
curl http://localhost:8000/health

# Test prediction
python ml/prediction_script.py
```

## ðŸ“ˆ Performance

### Model Performance
- **Accuracy**: 78.86%
- **Precision**: 0.79
- **Recall**: 0.89
- **F1-Score**: 0.84

### API Performance
- **Response Time**: < 100ms for predictions
- **Throughput**: 100+ requests/second
- **Scalability**: Horizontal scaling ready

## ðŸ”’ Security Features

- Input validation with Pydantic models
- SQL injection prevention with parameterized queries
- CORS configuration
- Error handling and logging
- Data sanitization

## ðŸ“ Documentation

- **API Documentation**: Available at `http://localhost:8000/docs`
- **ERD Diagram**: `docs/ERD_diagram.md`
- **Code Comments**: Comprehensive inline documentation
- **Setup Guide**: This README

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

## ðŸ“„ License

This project is created for educational purposes as part of the Database - Prediction Pipeline assignment.

## ðŸ‘¥ Team Contributions

- **Database Design**: Complete MySQL and MongoDB schema
- **API Development**: Full FastAPI implementation with CRUD operations
- **ML Pipeline**: Model training and prediction scripts
- **Documentation**: Comprehensive README and ERD diagram
- **Testing**: End-to-end testing and validation

---

**GitHub Repository**: [Link to your repository]

**Assignment**: Formative 1 - Database - Prediction Pipeline 
=======
<<<<<<< HEAD
# Loan Prediction Database System

A comprehensive database system for loan application analysis and prediction using both MySQL (relational) and MongoDB (NoSQL) databases.

## ðŸ“Š Dataset

This project uses the `loan_applications.csv` dataset containing loan application data with the following features:
- **Loan_ID**: Unique identifier for each loan application
- **applicant_id**: Applicant identifier
- **LoanAmount**: Requested loan amount
- **Loan_Amount_Term**: Loan term in months
- **Credit_History**: Credit history indicator (0/1)
- **Property_Area**: Property area type (Urban/Rural/Semiurban)
- **Loan_Status**: Application outcome (Y/N)

## ðŸ—„ï¸ Database Design

### MySQL Schema (Relational Database)

The MySQL database follows a normalized design with **5 tables**:

#### 1. **applicants** (Primary Entity)
- `applicant_id` (PK) - Primary key
- `first_name`, `last_name`, `email`, `phone`
- `date_of_birth`, `created_at`, `updated_at`

#### 2. **loan_applications** (Main Entity)
- `loan_id` (PK) - Primary key
- `applicant_id` (FK) - Foreign key to applicants
- `loan_amount` - Requested loan amount
- `loan_amount_term_id` (FK) - Foreign key to loan_terms
- `credit_history` - Credit history indicator
- `property_area_id` (FK) - Foreign key to property_areas
- `loan_status` - Application outcome (Y/N)
- `application_date`, `decision_date`

#### 3. **property_areas** (Lookup Table)
- `area_id` (PK) - Primary key
- `area_name` - Area type (Urban/Rural/Semiurban)
- `description`, `created_at`

#### 4. **loan_terms** (Lookup Table)
- `term_id` (PK) - Primary key
- `term_months` - Loan term in months
- `description`, `created_at`

#### 5. **application_logs** (Audit Table)
- `log_id` (PK) - Primary key
- `loan_id` (FK) - Foreign key to loan_applications
- `action_type` - Type of action (INSERT/UPDATE/DELETE)
- `old_status`, `new_status` - Status changes
- `changed_by`, `change_timestamp`

### MongoDB Schema (NoSQL Database)

The MongoDB database uses **collections** with the same logical structure:

- **applicants** - Applicant information
- **loan_applications** - Main loan application data
- **property_areas** - Property area lookup data
- **loan_terms** - Loan term lookup data
- **application_logs** - Audit trail

## ðŸ”§ Database Features

### Stored Procedures (MySQL)
1. **ValidateLoanApplication** - Validates loan application data
   - Checks loan amount validity
   - Validates credit history values
   - Returns validation status and messages

2. **PredictLoanApproval** - Predicts loan approval probability
   - Analyzes historical data patterns
   - Returns approval probability and recommendation
   - Uses machine learning-like approach

### Triggers (MySQL)
1. **after_loan_application_insert** - Logs new applications
2. **after_loan_application_update** - Logs status changes
3. **after_loan_application_delete** - Logs deletions

### Views (MySQL)
1. **loan_application_summary** - Complete application details
2. **approval_stats_by_area** - Approval statistics by property area
3. **approval_stats_by_credit** - Approval statistics by credit history

### MongoDB Functions
1. **predictLoanApproval()** - MongoDB equivalent of prediction stored procedure
2. **validateLoanApplication()** - MongoDB equivalent of validation stored procedure

## ðŸš€ Setup Instructions

### Prerequisites
- MySQL Server (8.0+)
- MongoDB Server (5.0+)
- Python 3.8+

### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Configure Database Connections
Update the connection settings in `setup_database.py`:
```python
# MySQL
host='localhost'
user='root'
password='your_password'
database='loan_prediction_db'

# MongoDB
mongodb://localhost:27017/
```

### 3. Set Up MySQL Database
```bash
# Connect to MySQL and run the schema
mysql -u root -p < database_schema.sql
```

### 4. Set Up MongoDB Database
```bash
# Connect to MongoDB and run the schema
mongosh < mongodb_schema.js
```

### 5. Load Data and Generate ERD
```bash
# Load CSV data into both databases
python setup_database.py

# Generate ERD diagram
python create_erd.py
```

### 6. Test Your Database Setup
```bash
# Quick check to verify databases are working
python quick_check.py

# Comprehensive test suite
python test_database.py
```

## ðŸ“ˆ ERD Diagram

The Entity Relationship Diagram shows:
- **5 tables** with proper normalization
- **Primary and Foreign Key relationships**
- **1:N relationships** between entities
- **Color-coded table types**:
  - ðŸŸ¢ Primary Entity (Applicants)
  - ðŸ”µ Main Entity (Loan Applications)
  - ðŸŸ  Lookup Tables (Property Areas, Loan Terms)
  - âšª Audit Tables (Application Logs)

## ðŸ” Sample Queries

### MySQL Queries
```sql
-- Get approval statistics by area
SELECT * FROM approval_stats_by_area;

-- Predict loan approval for new application
CALL PredictLoanApproval(100000, 1, 'Urban', @prob, @rec);
SELECT @prob, @rec;

-- Validate loan application
CALL ValidateLoanApplication('TEST001', 100000, 1, @valid, @msg);
SELECT @valid, @msg;
```

### MongoDB Queries
```javascript
// Get approval statistics by area
db.approval_stats_by_area.find();

// Predict loan approval
predictLoanApproval(100000, 1, "Urban");

// Validate loan application
validateLoanApplication("TEST001", 100000, 1);
```

## ðŸ“Š Data Analysis Features

### Automated Analytics
- **Approval Rate Analysis** by property area and credit history
- **Trend Analysis** using historical data
- **Risk Assessment** based on application patterns
- **Performance Metrics** for loan processing

### Machine Learning Integration
- **Historical Pattern Analysis** for prediction
- **Risk Scoring** based on multiple factors
- **Automated Decision Support** system

## ðŸ›¡ï¸ Data Integrity & Security

### Constraints
- **Primary Key Constraints** on all tables
- **Foreign Key Constraints** for referential integrity
- **Check Constraints** for data validation
- **Unique Constraints** where appropriate

### Audit Trail
- **Complete Change Logging** for all modifications
- **User Tracking** for accountability
- **Timestamp Tracking** for compliance

## ðŸ“ Project Structure

```
Database---Prediction-Pipeline/
â”œâ”€â”€ loan_applications.csv          # Source dataset
â”œâ”€â”€ database_schema.sql           # MySQL schema and procedures
â”œâ”€â”€ mongodb_schema.js             # MongoDB schema and functions
â”œâ”€â”€ setup_database.py             # Data loading script
â”œâ”€â”€ create_erd.py                 # ERD diagram generator
â”œâ”€â”€ test_database.py              # Comprehensive database testing
â”œâ”€â”€ quick_check.py                # Quick database verification
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ env_example.txt               # Environment configuration
â”œâ”€â”€ ERD_Diagram.png              # Generated ERD diagram
â”œâ”€â”€ ERD_Diagram.pdf              # Generated ERD diagram (PDF)
â””â”€â”€ README.md                    # This file
```

## ðŸŽ¯ Key Achievements

âœ… **Normalized Database Design** with 5 tables  
âœ… **Primary and Foreign Key Relationships** properly defined  
âœ… **Stored Procedures** for validation and prediction  
âœ… **Triggers** for automated audit logging  
âœ… **Views** for reporting and analytics  
âœ… **MongoDB Collections** with equivalent functionality  
âœ… **ERD Diagram** with professional visualization  
âœ… **Complete Data Pipeline** from CSV to both databases  
âœ… **Comprehensive Documentation** and setup instructions  

## ðŸ”® Future Enhancements

- **Real-time Analytics Dashboard**
- **Advanced Machine Learning Models**
- **API Integration** for external systems
- **Enhanced Security Features**
- **Performance Optimization** for large datasets

---

**Note**: This system demonstrates a complete database design and implementation for loan prediction, meeting all requirements for the assignment including proper normalization, stored procedures, triggers, and both relational and NoSQL database implementations.
=======
# Database---Prediction-Pipeline


#link to the dataset
[https://www.kaggle.com/datasets/altruistdelhite04/loan-prediction-problem-dataset/data?select=train_u6lujuX_CVtuZ9i.csv](https://www.kaggle.com/datasets/altruistdelhite04/loan-prediction-problem-dataset/data?select=train_u6lujuX_CVtuZ9i.csv)
>>>>>>> c3126528bfd51e4de46ddf94225f43ae386d3b9b
>>>>>>> 2f891f6c837c022373fcdd91d92764e638e9f13e
